---
layout: r
title: Introduction to R

---

<h1 id="do-samples-come-from-the-same-or-different-populations">Do Samples Come From The Same Or Different Populations?</h1>
<p>We use the following methods to test whether samples are drawn from populations with different means, or test whether one sample is drawn from a population with a mean different from some theoretical mean.</p>
<hr />
<p><em>Functions:</em> t.test, wilcox.test</p>
<p><em>Rcode:</em> <a href="../statistics/testing-populations.r">.r</a> <a href="../statistics/testing-populations.txt">.txt</a></p>
<hr />
<p><strong>Type of data:</strong> Integer or continuous in two or more groups.</p>
<hr />
<p>We can continue to use the small bird data...</p>
<pre class="sourceCode r"><code class="sourceCode r">BirdData &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
            <span class="dt">Tarsus  =</span> <span class="kw">c</span>(<span class="fl">22.3</span>, <span class="fl">19.7</span>, <span class="fl">20.8</span>, <span class="fl">20.3</span>, <span class="fl">20.8</span>, <span class="fl">21.5</span>, <span class="fl">20.6</span>, <span class="fl">21.5</span>),
            <span class="dt">Head    =</span> <span class="kw">c</span>(<span class="fl">31.2</span>, <span class="fl">30.4</span>, <span class="fl">30.6</span>, <span class="fl">30.3</span>, <span class="fl">30.3</span>, <span class="fl">30.8</span>, <span class="fl">32.5</span>, <span class="fl">31.6</span>),
            <span class="dt">Weight  =</span> <span class="kw">c</span>(<span class="fl">9.5</span>, <span class="fl">13.8</span>, <span class="fl">14.8</span>, <span class="fl">15.2</span>, <span class="fl">15.5</span>, <span class="fl">15.6</span>, <span class="fl">15.6</span>, <span class="fl">15.7</span>),
            <span class="dt">Wingcrd =</span> <span class="kw">c</span>(<span class="dv">59</span>, <span class="dv">55</span>, <span class="fl">53.5</span>, <span class="dv">55</span>, <span class="fl">52.5</span>, <span class="fl">57.5</span>, <span class="dv">53</span>, <span class="dv">55</span>),
            <span class="dt">Species =</span> <span class="kw">c</span>(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;A&#39;</span>, <span class="st">&#39;A&#39;</span>, <span class="st">&#39;A&#39;</span>, <span class="st">&#39;A&#39;</span>,  <span class="st">&#39;B&#39;</span>, <span class="st">&#39;B&#39;</span>, <span class="st">&#39;B&#39;</span>)
            )</code></pre>
<h1 id="one-sample">One sample</h1>
<h2 id="t-test-t.testx-mu">t-test: t.test(x = , mu =)</h2>
<p>First, we can test whether one sample is drawn from a population with a mean different from a theoretical mean, using a one-sample t-test.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Student%27s_t-test#One-sample_t-test">one-sample t-test</a> asks whether our data are drawn from a population whose true mean is some value we specify.</p>
<p>In this case, we can ask whether the sparrow's tarsus data is drawn from a population that has a mean (<code>mu</code>) of 20.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(BirdData$Tarsus, <span class="dt">mu =</span> <span class="dv">20</span>)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  BirdData$Tarsus
## t = 3.2786, df = 7, p-value = 0.01351
## alternative hypothesis: true mean is not equal to 20
## 95 percent confidence interval:
##  20.26135 21.61365
## sample estimates:
## mean of x 
##   20.9375</code></pre>
<p>The <code>p = 0.01351</code> suggests that our sparrows are different.</p>
<hr />
<h1 id="two-samples">Two samples</h1>
<h2 id="independent-two-sample-t-test-t.testx-y">independent two-sample t-test: t.test(x = , y =)</h2>
<p>Two compare the means of two samples that were taken independently, we can use <code>t.test()</code>. By default, R assumes that variances are not equal, and adjusts for this by running a Welch t-test.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(<span class="dt">x =</span> BirdData$Tarsus[BirdData$Species ==<span class="st"> &#39;A&#39;</span>], 
       <span class="dt">y =</span> BirdData$Tarsus[BirdData$Species ==<span class="st"> &#39;B&#39;</span>])</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  BirdData$Tarsus[BirdData$Species == &quot;A&quot;] and BirdData$Tarsus[BirdData$Species == &quot;B&quot;]
## t = -0.80033, df = 5.9988, p-value = 0.454
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.7041641  0.8641641
## sample estimates:
## mean of x mean of y 
##     20.78     21.20</code></pre>
<p>Species A and B have similar tarsus lengths.</p>
<p>To run the Student's t-test, that does assume equal variance, set <code>var.equal = TRUE</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(<span class="dt">x =</span> BirdData$Tarsus[BirdData$Species ==<span class="st"> &#39;A&#39;</span>], 
       <span class="dt">y =</span> BirdData$Tarsus[BirdData$Species ==<span class="st"> &#39;B&#39;</span>],
       <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  BirdData$Tarsus[BirdData$Species == &quot;A&quot;] and BirdData$Tarsus[BirdData$Species == &quot;B&quot;]
## t = -0.68349, df = 6, p-value = 0.5198
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.923607  1.083607
## sample estimates:
## mean of x mean of y 
##     20.78     21.20</code></pre>
<h2 id="paired-t-test-t.testx-y-paired-true">Paired t-test: t.test(x = , y = , paired = TRUE)</h2>
<p>If we have observations before and after a treatment, or of two matched subjects with different treatments, we can run a paired t-test. R relies on the relative position to determine the pairing, so make sure that this is correct.</p>
<p>Pairing the data gives us more statistical power, because random inbetween subject variation has been eliminated. But, we lose degrees of freedom because each pair is now the test unit, rather than the individual.</p>
<pre class="sourceCode r"><code class="sourceCode r">before &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">20</span>, <span class="dv">15</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">15</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">15</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">15</span>, <span class="dv">10</span>, <span class="dv">5</span>)
after &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">23</span>, <span class="dv">16</span>, <span class="dv">10</span>, <span class="dv">4</span>, <span class="dv">22</span>, <span class="dv">15</span>, <span class="dv">12</span>, <span class="dv">7</span>, <span class="dv">21</span>, <span class="dv">16</span>, <span class="dv">11</span>, <span class="dv">5</span>, <span class="dv">22</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">6</span>)

<span class="kw">t.test</span>(before, after)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  before and after
## t = -0.40876, df = 29.755, p-value = 0.6856
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -5.248256  3.498256
## sample estimates:
## mean of x mean of y 
##    12.500    13.375</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(before, after, <span class="dt">paired =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  before and after
## t = -3.0502, df = 15, p-value = 0.0081
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.4864388 -0.2635612
## sample estimates:
## mean of the differences 
##                  -0.875</code></pre>
<p>In the above cases, we have specified <code>x</code> and <code>y</code>. Depending how you have your data organised, a formula can also be used.</p>
<p>The paired t-test is equivalent to testing whether difference between each pair of observations has a population mean of 0.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(<span class="dt">x =</span> before -<span class="st"> </span>after, <span class="dt">mu =</span> <span class="dv">0</span>, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  before - after
## t = -3.0502, df = 15, p-value = 0.0081
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -1.4864388 -0.2635612
## sample estimates:
## mean of x 
##    -0.875</code></pre>
<p>The t-test assumes that the <em>data</em> for each group or sample follow a normal distribution and were sampled independently from the two populations. The Student's t-test assume equal variances, but is robust if sample sizes are equal; Welch's t-test is robust to unequal variance even if sample sizes are different.</p>
<h3 id="non-parametric-wilcox.test">Non-parametric: wilcox.test()</h3>
<p>As with <code>t.test()</code>, the <code>wilcox.test()</code> function can be modified for one or two samples, paired or unpaired.</p>
<p>For independent (unpaired) samples, it is called the <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann-Whitney U test</a>. For paired samples, it is known as the <a href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test">Wilcoxon signed-rank test</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(<span class="dt">x =</span> BirdData$Tarsus[BirdData$Species ==<span class="st"> &#39;A&#39;</span>], 
            <span class="dt">y =</span> BirdData$Tarsus[BirdData$Species ==<span class="st"> &#39;B&#39;</span>])</code></pre>
<pre><code>## Warning in wilcox.test.default(x = BirdData$Tarsus[BirdData$Species ==
## &quot;A&quot;], : cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  BirdData$Tarsus[BirdData$Species == &quot;A&quot;] and BirdData$Tarsus[BirdData$Species == &quot;B&quot;]
## W = 5, p-value = 0.5462
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<hr />
<h1 id="more-than-two-samples">More than two samples</h1>
<h2 id="analysis-of-variance">Analysis of Variance</h2>
<p>In its simplest form, <a href="https://en.wikipedia.org/wiki/Analysis_of_variance">ANOVA</a> is a statistical test of whether or not the means of several groups are equal, and therefore generalizes the t-test to more than two groups. It is akin to running multiple two-sample t-tests.</p>
<p>ANOVA has the following assumptions.</p>
<ul>
<li>Independence of observations,<br /></li>
<li>Normality - the distributions of the <em>residuals</em> are normal,<br /></li>
<li>Equality (or &quot;homogeneity&quot;) of variances (called homoscedasticity) - the variance of data in groups should be the same.</li>
</ul>
<h2 id="one-way-anova-aov">One-way ANOVA: aov()</h2>
<p>One-way analysis of variance (ANOVA) is used to determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups.</p>
<p>It tests the null hypothesis that the means of all groups are equal. Details of the specifics of ANOVA are described <a href="../anova-explained.html">here</a></p>
<p>If it returns a statistically significant result, we accept the alternative hypothesis: At least two group means are statistically significantly different from each other.</p>
<p>However, ANOVA cannot tell you <em>which</em> specific group/s is significantly different from which other. To determine this, a <em>post-hoc</em> test must be carried out.</p>
<p>We will illustrate this using the sparrow data set.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#dat &lt;- read.table(file = &quot;http://www.simonqueenborough.info/R/data/sparrows.txt&quot;, header = TRUE)</span>
dat &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&#39;~/Dropbox/MyLab/website/R/data/sparrows.txt&#39;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">sep =</span> <span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)</code></pre>
<p>We want to make sure that the observers who collected the data were not biased in any way, i.e., there was no observer that consistently measured low or high. If sparrows were assigned at random to observers, we would not expect any difference between the observers in the sparrow measurements.</p>
<p>We can test this question with a one-way ANOVA.</p>
<p>First, it will make our lives a tiny bit easier to convert Observer to a factor.</p>
<pre class="sourceCode r"><code class="sourceCode r">dat$fObserver &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dat$Observer)</code></pre>
<p>Then, we can plot the data (two different ways, of course!).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">1</span>)

<span class="co"># 1. First a boxplot</span>
<span class="kw">boxplot</span>(dat$Tarsus ~<span class="st"> </span>dat$fObserver,
       <span class="dt">xlab =</span> <span class="st">&#39;Observer&#39;</span>)

<span class="co"># 2. Then, a barplot:</span>
## use tapply() to get means and sd
MeanTarsus &lt;-<span class="st"> </span><span class="kw">tapply</span>(dat$Tarsus, dat$fObserver, mean)
SDTarsus   &lt;-<span class="st"> </span><span class="kw">tapply</span>(dat$Tarsus, dat$fObserver, sd)

## calculate mid-points of bars, to plot error bars
MidPoints &lt;-<span class="st"> </span><span class="kw">barplot</span>(MeanTarsus, <span class="dt">plot =</span> <span class="ot">FALSE</span>)

<span class="kw">barplot</span>(MeanTarsus, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),
       <span class="dt">xlab =</span> <span class="st">&#39;Observer&#39;</span>)
<span class="kw">segments</span>(<span class="dt">x0 =</span> MidPoints, <span class="dt">x1 =</span> MidPoints,
         <span class="dt">y0 =</span> MeanTarsus +<span class="st"> </span>SDTarsus, <span class="dt">y1 =</span> MeanTarsus -<span class="st"> </span>SDTarsus)</code></pre>
<div class="figure">
<img src="figure/unnamed-chunk-10-1.png" alt="Differences in Tarsus length measured by different Observers" /><p class="caption">Differences in Tarsus length measured by different Observers</p>
</div>
<p>The function <code>aov()</code> runs the ANOVA model. We need to provide a <code>formula =</code> argument, and can also give a <code>data =</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">m_obs &lt;-<span class="st"> </span><span class="kw">aov</span>(Tarsus ~<span class="st"> </span>fObserver, <span class="dt">data =</span> dat)
<span class="kw">summary</span>(m_obs)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## fObserver     6   19.1   3.181   3.793 0.000966 ***
## Residuals   972  815.3   0.839                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The <code>p = 0.000966</code> tells us that there are significant differences among observers. We will need to do a post-hoc test to identify which ones (see below).</p>
<p>In reality, <code>aov()</code> is a wrapper to <code>lm()</code> (i.e., the function aov calls the function lm) for fitting linear models to balanced or unbalanced experimental designs. The main difference from <code>lm()</code> is in the way <code>print()</code>, <code>summary()</code> and so on handle the fit: this is expressed in the traditional language of the analysis of variance rather than that of linear models. This also means that it is easy to include both categorical and continuous variables as predictors in a model (we will come to this later).</p>
<p><em>Note:</em> <code>aov()</code> is designed for balanced designs, and the results can be hard to interpret without balance: beware that missing values in the response(s) will likely lose the balance.</p>
<h3 id="non-parametric-one-way-anova-kruskal-wallis-test">Non-parametric one-way ANOVA: Kruskal-Wallis Test</h3>
<p>If the data do not meet the assumptions of a parametric ANOVA, we can use a non-parametric alternative. In this case, the <a href="https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance">Kruskal-Wallis Test</a>, or one-way ANOVA on ranks. It extends the Mann-Whitney U Test to more than two groups.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kruskal.test</span>(Tarsus ~<span class="st"> </span>fObserver, <span class="dt">data =</span> dat)</code></pre>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  Tarsus by fObserver
## Kruskal-Wallis chi-squared = 38.875, df = 6, p-value = 7.574e-07</code></pre>
<h2 id="two-way-anova-aov">Two-way ANOVA: aov()</h2>
<p>A two-way ANOVA models the response as a function of two categorical variables, and can also include an interaction between them. (So that we keep using the same sparrow data, we will look at how Tarsus length varies between the different species and sexes, although there are only two levels of each).</p>
<p>First, we run the simple additive model. This model is testing for differences between species and between the sexes pooled over species.</p>
<pre class="sourceCode r"><code class="sourceCode r">m_additive &lt;-<span class="st"> </span><span class="kw">aov</span>(Tarsus ~<span class="st"> </span>Species +<span class="st"> </span>Sex, <span class="dt">data =</span> dat)
<span class="kw">summary</span>(m_additive)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
## Species       1  391.7   391.7  1022.2 &lt;2e-16 ***
## Sex           1   68.8    68.8   179.5 &lt;2e-16 ***
## Residuals   976  374.0     0.4                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>P &lt; 0.05 for both Species and Sex, suggesting that tarsus length differs significantly in both.</p>
<p>To test whether the differences between the sexes are different in each species (i.e., is there an <em>interaction</em> between sex and species), we modify the model with <code>*</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">m_interaction &lt;-<span class="st"> </span><span class="kw">aov</span>(Tarsus ~<span class="st"> </span>Species *<span class="st"> </span>Sex, <span class="dt">data =</span> dat)
<span class="kw">summary</span>(m_interaction)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq  F value Pr(&gt;F)    
## Species       1  391.7   391.7 1021.912 &lt;2e-16 ***
## Sex           1   68.8    68.8  179.492 &lt;2e-16 ***
## Species:Sex   1    0.3     0.3    0.709    0.4    
## Residuals   975  373.7     0.4                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Here, P = 0.4, suggesting that the difference in Tarsus length between males and females does not vary between the species.</p>
<p>A more detailed calculation of ANOVA in R is provided <a href="../statistics/anova-explained.html">here</a></p>
<h2 id="post-hoc-tests-tukeyhsd">Post-hoc tests: TukeyHSD</h2>
<p>To compare the significant difference across all the group means <a href="https://en.wikipedia.org/wiki/Tukey%27s_range_test">Tukeys Honest Significant Differences</a> test is often used. Tukey's test is essentially a t-test, except that it corrects for the fact that you are making multiple comparisons (when making multiple comparisons, the chance of making a <a href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors">Type I error</a>---a false positive---increases). Tukey's test corrects for that, so is more suitable single test for multiple comparisons than a running multiple t-tests.</p>
<p>First, we look at the one-way ANOVA, differences between observers.</p>
<pre class="sourceCode r"><code class="sourceCode r">posthoc &lt;-<span class="st"> </span><span class="kw">TukeyHSD</span>(m_obs)
posthoc</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Tarsus ~ fObserver, data = dat)
## 
## $fObserver
##             diff         lwr         upr     p adj
## 3-2  0.266804979  0.03220683  0.50140313 0.0141868
## 4-2  0.009638554 -0.32632698  0.34560409 1.0000000
## 5-2  0.133333333 -0.29952798  0.56619464 0.9710133
## 6-2 -0.068831169 -0.33753254  0.19987020 0.9887784
## 7-2  0.346000000 -0.06763922  0.75963922 0.1709119
## 8-2 -0.029357798 -0.33239207  0.27367647 0.9999552
## 4-3 -0.257166425 -0.60155215  0.08721930 0.2929550
## 5-3 -0.133471646 -0.57290036  0.30595707 0.9729768
## 6-3 -0.335636148 -0.61479401 -0.05647829 0.0073020
## 7-3  0.079195021 -0.34131192  0.49970196 0.9979097
## 8-3 -0.296162777 -0.60850626  0.01618071 0.0762933
## 5-4  0.123694779 -0.37723849  0.62462805 0.9907668
## 6-4 -0.078469723 -0.44693364  0.28999419 0.9958615
## 7-4  0.336361446 -0.14805845  0.82078134 0.3828507
## 8-4 -0.038996352 -0.43319808  0.35520537 0.9999493
## 6-5 -0.202164502 -0.66070756  0.25637855 0.8508450
## 7-5  0.212666667 -0.34335375  0.76868709 0.9188436
## 8-5 -0.162691131 -0.64216071  0.31677844 0.9534703
## 7-6  0.414831169 -0.02561204  0.85527438 0.0801807
## 8-6  0.039473371 -0.29923386  0.37818060 0.9998674
## 8-7 -0.375357798 -0.83754776  0.08683216 0.1997785</code></pre>
<p>Here, looking down the list of P values, only two comparisons are significant: 3-2 and 6-3.</p>
<p>Then, the two-way ANOVA.</p>
<pre class="sourceCode r"><code class="sourceCode r">posthoc &lt;-<span class="st"> </span><span class="kw">TukeyHSD</span>(m_additive)
posthoc</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Tarsus ~ Species + Sex, data = dat)
## 
## $Species
##                diff       lwr       upr p adj
## SSTS-SESP -1.942702 -2.061942 -1.823462     0
## 
## $Sex
##                  diff       lwr       upr p adj
## Male-Female 0.5802367 0.4951247 0.6653487     0</code></pre>
<hr />


<p>Updated: 2016-10-15</p>
